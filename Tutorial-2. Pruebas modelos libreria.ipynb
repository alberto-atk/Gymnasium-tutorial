{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3731c0c6",
   "metadata": {},
   "source": [
    "# Pruebas básicas\n",
    "Una vez vistas las clases por las que está formada gymnasium y de que trata, se van a realizar varias pruebas con un entorno, en concreto CartPole para ver el funcionamiento general de la librería y sus posibilidades. <br>\n",
    "\n",
    "El entorno *CartPole*, cumple las siguientes características:\n",
    "- **Espacio de acciones** \n",
    "    0. para mover el carro a la izquierda\n",
    "    1. para mover el carro a la derecha\n",
    "- **Espacio de observaciones**:\n",
    "    0. Posición del carro\n",
    "    1. Velocidad del carro\n",
    "    2. Ángulo del palo\n",
    "    3. Velocidad angular del palo\n",
    "    \n",
    "La misión del entorno, es mantener el palo encima del carro el máximo tiempo posible.\n",
    "\n",
    "En esta primera prueba, las acciones que se van a tomar van a ser random, es decir, no se va a seguir ninguna política ni ningún tipo de entrenamiento. Este ejemplo, es únicamente para ver como sería una salida típica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38ef0e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alberto/anaconda3/envs/gymnasium/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/alberto/anaconda3/envs/gymnasium/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:249: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio terminado después de 10 timesteps\n",
      "Episodio terminado después de 18 timesteps\n",
      "Episodio terminado después de 22 timesteps\n",
      "Episodio terminado después de 14 timesteps\n",
      "Episodio terminado después de 18 timesteps\n",
      "Episodio terminado después de 16 timesteps\n",
      "Episodio terminado después de 12 timesteps\n",
      "Episodio terminado después de 11 timesteps\n",
      "Episodio terminado después de 25 timesteps\n",
      "Episodio terminado después de 16 timesteps\n",
      "Episodio terminado después de 23 timesteps\n",
      "Episodio terminado después de 19 timesteps\n",
      "Episodio terminado después de 12 timesteps\n",
      "Episodio terminado después de 32 timesteps\n",
      "Episodio terminado después de 10 timesteps\n",
      "Episodio terminado después de 43 timesteps\n",
      "Episodio terminado después de 16 timesteps\n",
      "Episodio terminado después de 18 timesteps\n",
      "Episodio terminado después de 9 timesteps\n",
      "Episodio terminado después de 17 timesteps\n",
      "Tiempo medio: 18.05\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "observation, info = env.reset() #primer reset necesario\n",
    "\n",
    "total = 0\n",
    "\n",
    "for episode in range(20):\n",
    "    observation, info = env.reset()\n",
    "    for t in range(1000): #tiempo que está en ejecución el entorno\n",
    "        action = env.action_space.sample() #accion random\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        if terminated or truncated: #finalizada la ejecución del anterior\n",
    "            observation, info = env.reset()\n",
    "            total += (t+1)\n",
    "            print(\"Episodio terminado después de {} timesteps\".format((t+1)))\n",
    "            break\n",
    "            \n",
    "print(\"Tiempo medio: {}\".format(total/20))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889fb5f4",
   "metadata": {},
   "source": [
    "Una posible política para este problema sería que el palo intentase estar centrado, ya que la meta es mantenerse el máximo tiempo posible. Para ello, si el palo es mayor que 0, se estará cayendo a la derecha por lo que habrá que mover el carro a la derecha también. Un ejemplo de implementación sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e9d77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio terminado después de 39 timesteps\n",
      "Episodio terminado después de 34 timesteps\n",
      "Episodio terminado después de 50 timesteps\n",
      "Episodio terminado después de 34 timesteps\n",
      "Episodio terminado después de 48 timesteps\n",
      "Episodio terminado después de 44 timesteps\n",
      "Episodio terminado después de 39 timesteps\n",
      "Episodio terminado después de 25 timesteps\n",
      "Episodio terminado después de 59 timesteps\n",
      "Episodio terminado después de 25 timesteps\n",
      "Episodio terminado después de 43 timesteps\n",
      "Episodio terminado después de 37 timesteps\n",
      "Episodio terminado después de 46 timesteps\n",
      "Episodio terminado después de 35 timesteps\n",
      "Episodio terminado después de 35 timesteps\n",
      "Episodio terminado después de 41 timesteps\n",
      "Episodio terminado después de 53 timesteps\n",
      "Episodio terminado después de 54 timesteps\n",
      "Episodio terminado después de 49 timesteps\n",
      "Episodio terminado después de 45 timesteps\n",
      "Tiempo medio: 41.75\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "observation, info = env.reset() \n",
    "\n",
    "total = 0\n",
    "\n",
    "for episode in range(20):\n",
    "    observation, info = env.reset()\n",
    "    for t in range(1000): \n",
    "        if observation[2] > 0.0:\n",
    "            observation, reward, terminated, truncated, info = env.step(1)\n",
    "        else:\n",
    "            observation, reward, terminated, truncated, info = env.step(0)\n",
    "\n",
    "        if terminated or truncated: \n",
    "            observation, info = env.reset()\n",
    "            total += (t+1)\n",
    "            print(\"Episodio terminado después de {} timesteps\".format((t+1)))\n",
    "            break\n",
    "            \n",
    "print(\"Tiempo medio: {}\".format(total/20))\n",
    "env.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631d757b",
   "metadata": {},
   "source": [
    "Después de esta ejecución, se puede comprobar que se duplica el tiempo medio que aguanta el palo, por lo que la política escogida sería correcta. <br> <br>\n",
    "\n",
    "Otra forma de posible, sería que además del ángulo, también la velocidad angular (*observation[3]*) sea positiva, ya que en casos en los que este prácticamente equilibrado, se haría un movimiento que podría ser innecesario. Un ejemplo de esta política sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7009e9cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio terminado después de 135 timesteps\n",
      "Episodio terminado después de 117 timesteps\n",
      "Episodio terminado después de 196 timesteps\n",
      "Episodio terminado después de 142 timesteps\n",
      "Episodio terminado después de 180 timesteps\n",
      "Episodio terminado después de 135 timesteps\n",
      "Episodio terminado después de 181 timesteps\n",
      "Episodio terminado después de 118 timesteps\n",
      "Episodio terminado después de 165 timesteps\n",
      "Episodio terminado después de 220 timesteps\n",
      "Episodio terminado después de 168 timesteps\n",
      "Episodio terminado después de 131 timesteps\n",
      "Episodio terminado después de 216 timesteps\n",
      "Episodio terminado después de 177 timesteps\n",
      "Episodio terminado después de 123 timesteps\n",
      "Episodio terminado después de 191 timesteps\n",
      "Episodio terminado después de 196 timesteps\n",
      "Episodio terminado después de 134 timesteps\n",
      "Episodio terminado después de 156 timesteps\n",
      "Episodio terminado después de 229 timesteps\n",
      "Tiempo medio: 165.5\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "observation, info = env.reset() \n",
    "\n",
    "total = 0\n",
    "\n",
    "for episode in range(20):\n",
    "    observation, info = env.reset()\n",
    "    for t in range(1000): \n",
    "        if observation[2] > 0.0 and observation[3] > 0.0:\n",
    "            observation, reward, terminated, truncated, info = env.step(1)\n",
    "        else:\n",
    "            observation, reward, terminated, truncated, info = env.step(0)\n",
    "\n",
    "        if terminated or truncated: \n",
    "            observation, info = env.reset()\n",
    "            total += (t+1)\n",
    "            print(\"Episodio terminado después de {} timesteps\".format((t+1)))\n",
    "            break\n",
    "            \n",
    "print(\"Tiempo medio: {}\".format(total/20))\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd7e5369",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb04f2c",
   "metadata": {},
   "source": [
    "Para aplicar Q-learning a este problema continuo, sería neceario discretizarlo para poder formar la tabla o utilizar Deep Q-learning. Para demostrar un caso de uso de Aprendizaje Reforzado combinado con la librería (uso común de la misma), se va a aplicar y así de esta misma forma, se puede comparar el resultado con el obtenido por las políticas anteriores.<br> <br>\n",
    "\n",
    "Las características del entorno, serían las comentadas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e176a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "class DQN():\n",
    "    def __init__(self, env):\n",
    "        self.max_episodes = 20000\n",
    "        self.max_actions = 99\n",
    "        \n",
    "        self.epsilon = 1.0 \n",
    "        self.max_epsilon = 1.0\n",
    "        self.min_epsilon = 0.01 \n",
    "        self.decay_rate = 0.005\n",
    "        self.learning_rate = 0.001\n",
    "        \n",
    "        \n",
    "        self.input_n = env.observation_space.shape[0]\n",
    "        self.output_n = env.action_space.n\n",
    "        \n",
    "        self.nn_model(env)\n",
    "        \n",
    "        print(self.output_n)\n",
    "        \n",
    "    def nn_model(self, env):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.input_n, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(24, input_dim=self.output_n, activation='linear'))\n",
    "        \n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "        \n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    def test(self, Q):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d9e7f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.DQN at 0x7f59e79cdac0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "DQN(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a9a1f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio terminado después de 10 timesteps\n",
      "Episodio terminado después de 21 timesteps\n",
      "Tiempo medio: 1.55\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "observation, info = env.reset() \n",
    "\n",
    "total = 0\n",
    "\n",
    "\n",
    "\n",
    "for episode in range(2):\n",
    "    observation, info = env.reset()\n",
    "    for t in range(1000): \n",
    "        \n",
    "        if random.uniform(0, 1) > epsilon:\n",
    "            action = np.argmax(take_action_nn(env,observation)) #obtiene accion de la tabla\n",
    "        else:\n",
    "            #se hace algo random (si no no se explora)\n",
    "            action = env.action_space.sample() \n",
    "            \n",
    "            \n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        if terminated or truncated: \n",
    "            observation, info = env.reset()\n",
    "            total += (t+1)\n",
    "            print(\"Episodio terminado después de {} timesteps\".format((t+1)))\n",
    "            break\n",
    "    \n",
    "    #Se reduce epsilon\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode) \n",
    "            \n",
    "print(\"Tiempo medio: {}\".format(total/20))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccce7844",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
